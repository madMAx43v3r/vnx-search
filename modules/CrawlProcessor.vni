package vnx.search;

module CrawlProcessor {
	
	vnx.TopicPtr input_url_index = "backend.url_index.updates";
	
	vnx.TopicPtr input_page_index = "backend.page_index.updates";
	
	vnx.TopicPtr output_crawl_stats = "backend.crawl_stats";
	
	string url_index_server = "UrlIndex";
	
	string crawl_frontend_server = "CrawlFrontend";
	
	int jump_cost = 3;
	
	int max_depth = 9;
	
	int reload_interval = 10800;		// [seconds / (depth + 1) ^ reload_power]
	
	int sync_interval = 3600;			// checking all urls [sec]
	
	int max_per_minute = 30;
	
	int max_num_pending = 50;
	
	int max_url_length = 256;
	
	int update_interval_ms = 200;
	
	float reload_power = 4;
	
	vector<string> protocols;
	
	vector<string> root_urls;
	
	vector<string> domain_blacklist;
	
	
	CrawlStats* get_stats(int limit) const;
	
	void handle(vnx.keyvalue.KeyValuePair sample);
	
}
